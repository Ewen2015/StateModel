---
title: "STAA 577 HW4"
author: "Enqun Wang"
date: "April 13, 2016"
output: pdf_document
---

Due: April 18 at noon

For this assignment, let's attempt to make a spam filter. Usually, this would involve a lot of text processing on a huge number of emails. In this case, someone has created a feature matrix, X, for us. X has rows given by individual emails and columns given by the number of each word or character that appears in that email, as well as three different numerical measures regarding capital letters (average length of consecutive capitals, longest sequence of consecutive capitals, and total number of capital letters). The response, Y , is given by the user supplied label marking that email as either spam (Y = 1) or not (Y = 0).

Here is a function that may be useful for this assignment:

```{r}
miss.class = function(pred.class, true.class, produceOutput = FALSE) {
  confusion.mat = table(pred.class, true.class)
  if (produceOutput) {
    return(1 - sum(diag(confusion.mat))/sum(confusion.mat))
  } else {
    print("miss-class")
    print(1 - sum(diag(confusion.mat))/sum(confusion.mat))
    print("confusion mat")
    print(confusion.mat)
    return(1 - sum(diag(confusion.mat))/sum(confusion.mat))
  }
}
# this can be called using: (assuming you make the
# appropriately named test predictions)
# miss.class(Y.hat, Y_0)
```

**1.** Read in the R data set `spam.Rdata` and read the documentation file `spambase.Documentation`. What object is loaded into memory? What objects are inside that object? How many emails do we have total? What features are in this data set?

```{r}
load("/Users/ewenwang/Dropbox/CSU-MAS/STAA 577/Homework/spam.rdata")
attributes(spam)
```

- A R data file is loaded into memory; it includes 6 lists, which are shown above. The dataset contains 4601 eamils with 58 features. 

**2.** Let's make a training and test set.

```{r}
train = spam$train
test = !train
X = spam$XdataF[train,]
X_0 = spam$XdataF[test,]
Y = factor(spam$Y[train])
Y_0 = factor(spam$Y[test])
```

How many observations are in the training set (that is, what is n)? How many observations are in the test set?

```{r}
length(train)
length(test)
```

- There are $`r length(train)`$ observations are in the training set; and $`r length(test)`$ observations in the test set.

**3.** Run the following code

```{r, message=F}
require(tree)

set.seed(2016)
out.tree = tree(Y~.,data=X)
tmp.tree = prune.tree(out.tree, best=3)
plot(tmp.tree)
text(tmp.tree)
```

What feature is split on first? Interpet that split point. Make the corresponding partition view for this dendrogram (you don't need to use R for this, just draw the right rectangles and be neat about it).

- The tree split on `punc_dollar` firts. If percentage of words in the e-mail that match `dollar` is greater 5.55%, then it is a spam. When `punc_dollar` is less than 0.0555, if `remove` is greater than 0.0555, it is a spam; otherwise, it is a non-spam.  

**4.** Fit an unpruned classification tree to the training data (hint: you've already done that on this h/w). Get the associated test misclassification rate and test confusion matrix.

```{r, message=F}
class.tree = predict(out.tree, X_0, type='class')
misRate = miss.class(class.tree, Y_0)
```

- The test misclassification rate is $`r misRate`$.

**5.** Prune the tree via weakest-link pruning (i.e. using the cv.tree and prune.misclass pair of functions as shown in lecture). What are this tree's test misclassification rate and test confusion matrix?

```{r}
out.tree.cv = cv.tree(out.tree, FUN = prune.misclass)

par(mfrow = c(1, 2))
plot(out.tree.cv$size, out.tree.cv$dev, type="b", 
     xlab = "Tree Size", ylab = "CV Error")
plot(out.tree.cv$k, out.tree.cv$dev, type="b", 
     xlab = expression(lambda), ylab = "CV Error")
par(mfrow = c(1, 1))

best.size = out.tree.cv$size[which.min(out.tree.cv$dev)]

out.tree = prune.misclass(out.tree, best=best.size)
class.tree = predict(out.tree, X_0, type='class')

misRate <- miss.class(class.tree, Y_0)
```

- The test misclassification rate is $`r misRate`$ and test confusion matrices is shown above.

**6.** Form a classifier with `randomForest` using the default `mtry`. What are the test misclassification rate and test confusion matrices? How does the test misclassification rate compare with the OOB misclassification rate?

```{r, message=F}
require(randomForest)

set.seed(2016)
out.rf = randomForest(X, Y, importance=T)
class.rf = predict(out.rf, X_0)

misRate <- miss.class(class.rf, Y_0)
out.rf
```

- The test misclassification rate is $`r misRate`$ and test confusion matrices is shown above. The OOB misclassification rate is 4.55%, which is less than the test misclassification rate.
